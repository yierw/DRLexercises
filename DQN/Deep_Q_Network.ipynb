{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Network (DQN)\n",
    "---\n",
    "In this notebook, you will implement a DQN agent with OpenAI Gym's LunarLander-v2 environment.\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: box2d in /opt/conda/lib/python3.6/site-packages (2.3.2)\n",
      "Requirement already satisfied: pyvirtualdisplay in /opt/conda/lib/python3.6/site-packages (0.2.5)\n",
      "Requirement already satisfied: EasyProcess in /opt/conda/lib/python3.6/site-packages (from pyvirtualdisplay) (0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "!pip3 install box2d\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "!python -m pip install pyvirtualdisplay\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explore the environment\n",
    "\n",
    "Initialize the environment in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "State shape:  (8,)\n",
      "Number of actions:  4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(0)\n",
    "print('State shape: ', env.observation_space.shape)\n",
    "print('Number of actions: ', env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SIZE = 8\n",
    "ACTION_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f854cb5d438>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "state = env.reset()\n",
    "for j in range(200):\n",
    "    action = env.action_space.sample() \n",
    "    img.set_data(env.render(mode='rgb_array')) \n",
    "    plt.axis('off')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = deque(maxlen = 500)  \n",
    "experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "state = env.reset()\n",
    "for j in range(200):\n",
    "    action = env.action_space.sample() \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    buffer.append(experience(state, action, reward, next_state, done))\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, buffer_size) :\n",
    "        self.memory = deque(maxlen = buffer_size)  \n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        x = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(x)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        samples = random.sample(self.memory, k = batch_size)\n",
    "        batch = self.experience(*zip(*samples))\n",
    "        states = torch.from_numpy(np.asarray(batch.state)).float().to(device)\n",
    "        actions = torch.from_numpy(np.asarray(batch.action)).long().view(-1,1).to(device) # discrete action space\n",
    "        rewards = torch.from_numpy(np.asarray(batch.reward)).float().view(-1,1).to(device)\n",
    "        next_states = torch.tensor(np.asarray(batch.next_state)).float().to(device)\n",
    "        # 0 for note finished, 1 for terminated\n",
    "        dones = torch.tensor([1 if done else 0 for done in batch.done]).float().view(-1,1).to(device)\n",
    "        return states, actions, rewards, next_states, dones\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ReplayBuffer(buffer_size = 500)\n",
    "\n",
    "state = env.reset()\n",
    "for j in range(200):\n",
    "    action = env.action_space.sample() \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.add(state, action, reward, next_state, done)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "print(len(memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8])\n",
      "torch.Size([16, 1])\n",
      "torch.Size([16, 1])\n",
      "torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "states, actions, rewards, next_states, dones = memory.sample(16)\n",
    "print(states.size())\n",
    "print(actions.size())\n",
    "print(rewards.size())\n",
    "print(dones.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Q network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size, seed):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(state_size, hidden_size),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Linear(hidden_size, action_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = self.main(state)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = QNetwork(STATE_SIZE, ACTION_SIZE, 16,1234).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Build agent\n",
    "\n",
    "wrap:\n",
    "\n",
    "1) act: select action according to policy derived from online network\n",
    "\n",
    "2) learn: take a GD step\n",
    "\n",
    "3) soft_update: update target network\n",
    "\n",
    "4) step: (overall control)add tuple to replay buffer, sample a batch from buffer to learn (call learn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 0.999             # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the target network\n",
    "\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, state_size, action_size, hidden_size, seed):\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.online_net = QNetwork(state_size, action_size, hidden_size, seed).to(device)\n",
    "        self.target_net = QNetwork(state_size, action_size, hidden_size, seed).to(device)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.online_net.parameters(), lr = LR)\n",
    "        self.memory = ReplayBuffer(buffer_size = BUFFER_SIZE)\n",
    "        self.t_step = 1 # tracking whether to update target network parameters\n",
    "        \n",
    "    def act(self, state, eps = 0.):\n",
    "        state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        # select action according to online network\n",
    "        self.online_net.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.online_net(state_tensor).argmax(1).item()\n",
    "        self.online_net.train()\n",
    "        \n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return action\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "        \n",
    "    def learn(self, experiences, gamma):\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        next_Q = self.target_net(next_states).max(1)[0].unsqueeze(1)\n",
    "        target = rewards + gamma*next_Q*(1-dones)\n",
    "        \n",
    "        prediction = self.online_net(states).gather(1, actions)\n",
    "        \n",
    "        loss = loss_fn(prediction, target.detach())\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def soft_update(self, tau):\n",
    "        for target_param, online_param in zip(self.target_net.parameters(), self.online_net.parameters()):\n",
    "            target_param.data.copy_(tau*target_param.data + (1.0-tau)*online_param.data)\n",
    "        \n",
    "        \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        self.t_step = self.t_step + 1\n",
    "        \n",
    "        # update target network\n",
    "        if (self.t_step % UPDATE_EVERY) == 0:\n",
    "            self.soft_update(TAU)\n",
    "            \n",
    "        # sample batch and learn\n",
    "        if len(self.memory)> BATCH_SIZE: \n",
    "            experiences = self.memory.sample(BATCH_SIZE)\n",
    "            self.learn(experiences, GAMMA)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(STATE_SIZE, ACTION_SIZE, 16,1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00507536,  0.93736935,  0.51406441, -0.21628388, -0.00587429,\n",
       "       -0.11644325,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.act(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for j in range(200):\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    agent.step(state, action, reward, next_state, done)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent.memory) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.t_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. train agent\n",
    "\n",
    "put all the pieces together, and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 0.999             # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the target network\n",
    "TMAX = 1000             # maximum steps per episode\n",
    "\n",
    "n_episodes = 800\n",
    "eps_start = 1.0\n",
    "eps_end = 0.01\n",
    "eps_decay = 0.995\n",
    "\n",
    "PRINT_EVERY = 50\n",
    "\n",
    "agent = Agent(STATE_SIZE, ACTION_SIZE, 64,1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50\tAverage Score: -210.01\n",
      "Episode 100\tAverage Score: -183.71\n",
      "Episode 150\tAverage Score: -196.72\n",
      "Episode 200\tAverage Score: -142.83\n",
      "Episode 250\tAverage Score: -121.70\n",
      "Episode 300\tAverage Score: -75.331\n",
      "Episode 350\tAverage Score: -29.57\n",
      "Episode 400\tAverage Score: -45.10\n",
      "Episode 437\tAverage Score: 2.0432\n",
      "Environment solved in 337 episodes!\tAverage Score: 2.04\n",
      "Episode 438\tAverage Score: 4.15\n",
      "Environment solved in 338 episodes!\tAverage Score: 4.15\n",
      "Episode 441\tAverage Score: 7.22\n",
      "Environment solved in 341 episodes!\tAverage Score: 7.22\n",
      "Episode 442\tAverage Score: 8.68\n",
      "Environment solved in 342 episodes!\tAverage Score: 8.68\n",
      "Episode 443\tAverage Score: 14.21\n",
      "Environment solved in 343 episodes!\tAverage Score: 14.21\n",
      "Episode 444\tAverage Score: 19.87\n",
      "Environment solved in 344 episodes!\tAverage Score: 19.87\n",
      "Episode 445\tAverage Score: 24.49\n",
      "Environment solved in 345 episodes!\tAverage Score: 24.49\n",
      "Episode 446\tAverage Score: 26.08\n",
      "Environment solved in 346 episodes!\tAverage Score: 26.08\n",
      "Episode 447\tAverage Score: 30.43\n",
      "Environment solved in 347 episodes!\tAverage Score: 30.43\n",
      "Episode 448\tAverage Score: 33.68\n",
      "Environment solved in 348 episodes!\tAverage Score: 33.68\n",
      "Episode 449\tAverage Score: 39.24\n",
      "Environment solved in 349 episodes!\tAverage Score: 39.24\n",
      "Episode 450\tAverage Score: 44.07\n",
      "\n",
      "Environment solved in 350 episodes!\tAverage Score: 44.07\n",
      "Episode 451\tAverage Score: 45.59\n",
      "Environment solved in 351 episodes!\tAverage Score: 45.59\n",
      "Episode 453\tAverage Score: 49.27\n",
      "Environment solved in 353 episodes!\tAverage Score: 49.27\n",
      "Episode 454\tAverage Score: 52.59\n",
      "Environment solved in 354 episodes!\tAverage Score: 52.59\n",
      "Episode 455\tAverage Score: 57.79\n",
      "Environment solved in 355 episodes!\tAverage Score: 57.79\n",
      "Episode 456\tAverage Score: 62.45\n",
      "Environment solved in 356 episodes!\tAverage Score: 62.45\n",
      "Episode 457\tAverage Score: 67.14\n",
      "Environment solved in 357 episodes!\tAverage Score: 67.14\n",
      "Episode 458\tAverage Score: 67.18\n",
      "Environment solved in 358 episodes!\tAverage Score: 67.18\n",
      "Episode 460\tAverage Score: 69.95\n",
      "Environment solved in 360 episodes!\tAverage Score: 69.95\n",
      "Episode 461\tAverage Score: 73.69\n",
      "Environment solved in 361 episodes!\tAverage Score: 73.69\n",
      "Episode 462\tAverage Score: 77.58\n",
      "Environment solved in 362 episodes!\tAverage Score: 77.58\n",
      "Episode 463\tAverage Score: 79.87\n",
      "Environment solved in 363 episodes!\tAverage Score: 79.87\n",
      "Episode 464\tAverage Score: 81.80\n",
      "Environment solved in 364 episodes!\tAverage Score: 81.80\n",
      "Episode 465\tAverage Score: 85.28\n",
      "Environment solved in 365 episodes!\tAverage Score: 85.28\n",
      "Episode 466\tAverage Score: 88.69\n",
      "Environment solved in 366 episodes!\tAverage Score: 88.69\n",
      "Episode 467\tAverage Score: 90.42\n",
      "Environment solved in 367 episodes!\tAverage Score: 90.42\n",
      "Episode 468\tAverage Score: 93.88\n",
      "Environment solved in 368 episodes!\tAverage Score: 93.88\n",
      "Episode 469\tAverage Score: 98.20\n",
      "Environment solved in 369 episodes!\tAverage Score: 98.20\n",
      "Episode 472\tAverage Score: 99.24\n",
      "Environment solved in 372 episodes!\tAverage Score: 99.24\n",
      "Episode 473\tAverage Score: 103.00\n",
      "Environment solved in 373 episodes!\tAverage Score: 103.00\n",
      "Episode 474\tAverage Score: 104.65\n",
      "Environment solved in 374 episodes!\tAverage Score: 104.65\n",
      "Episode 475\tAverage Score: 107.41\n",
      "Environment solved in 375 episodes!\tAverage Score: 107.41\n",
      "Episode 476\tAverage Score: 108.99\n",
      "Environment solved in 376 episodes!\tAverage Score: 108.99\n",
      "Episode 477\tAverage Score: 114.02\n",
      "Environment solved in 377 episodes!\tAverage Score: 114.02\n",
      "Episode 478\tAverage Score: 115.71\n",
      "Environment solved in 378 episodes!\tAverage Score: 115.71\n",
      "Episode 480\tAverage Score: 119.27\n",
      "Environment solved in 380 episodes!\tAverage Score: 119.27\n",
      "Episode 484\tAverage Score: 126.50\n",
      "Environment solved in 384 episodes!\tAverage Score: 126.50\n",
      "Episode 485\tAverage Score: 130.86\n",
      "Environment solved in 385 episodes!\tAverage Score: 130.86\n",
      "Episode 486\tAverage Score: 131.33\n",
      "Environment solved in 386 episodes!\tAverage Score: 131.33\n",
      "Episode 487\tAverage Score: 134.47\n",
      "Environment solved in 387 episodes!\tAverage Score: 134.47\n",
      "Episode 490\tAverage Score: 135.96\n",
      "Environment solved in 390 episodes!\tAverage Score: 135.96\n",
      "Episode 496\tAverage Score: 137.32\n",
      "Environment solved in 396 episodes!\tAverage Score: 137.32\n",
      "Episode 497\tAverage Score: 139.03\n",
      "Environment solved in 397 episodes!\tAverage Score: 139.03\n",
      "Episode 498\tAverage Score: 139.46\n",
      "Environment solved in 398 episodes!\tAverage Score: 139.46\n",
      "Episode 500\tAverage Score: 141.31\n",
      "\n",
      "Environment solved in 400 episodes!\tAverage Score: 141.31\n",
      "Episode 503\tAverage Score: 141.48\n",
      "Environment solved in 403 episodes!\tAverage Score: 141.48\n",
      "Episode 504\tAverage Score: 142.93\n",
      "Environment solved in 404 episodes!\tAverage Score: 142.93\n",
      "Episode 509\tAverage Score: 144.78\n",
      "Environment solved in 409 episodes!\tAverage Score: 144.78\n",
      "Episode 510\tAverage Score: 145.00\n",
      "Environment solved in 410 episodes!\tAverage Score: 145.00\n",
      "Episode 511\tAverage Score: 146.16\n",
      "Environment solved in 411 episodes!\tAverage Score: 146.16\n",
      "Episode 513\tAverage Score: 147.10\n",
      "Environment solved in 413 episodes!\tAverage Score: 147.10\n",
      "Episode 514\tAverage Score: 149.21\n",
      "Environment solved in 414 episodes!\tAverage Score: 149.21\n",
      "Episode 515\tAverage Score: 151.23\n",
      "Environment solved in 415 episodes!\tAverage Score: 151.23\n",
      "Episode 517\tAverage Score: 154.50\n",
      "Environment solved in 417 episodes!\tAverage Score: 154.50\n",
      "Episode 518\tAverage Score: 155.95\n",
      "Environment solved in 418 episodes!\tAverage Score: 155.95\n",
      "Episode 519\tAverage Score: 156.52\n",
      "Environment solved in 419 episodes!\tAverage Score: 156.52\n",
      "Episode 520\tAverage Score: 157.83\n",
      "Environment solved in 420 episodes!\tAverage Score: 157.83\n",
      "Episode 521\tAverage Score: 157.83\n",
      "Environment solved in 421 episodes!\tAverage Score: 157.83\n",
      "Episode 522\tAverage Score: 158.43\n",
      "Environment solved in 422 episodes!\tAverage Score: 158.43\n",
      "Episode 523\tAverage Score: 158.76\n",
      "Environment solved in 423 episodes!\tAverage Score: 158.76\n",
      "Episode 524\tAverage Score: 159.86\n",
      "Environment solved in 424 episodes!\tAverage Score: 159.86\n",
      "Episode 529\tAverage Score: 160.09\n",
      "Environment solved in 429 episodes!\tAverage Score: 160.09\n",
      "Episode 534\tAverage Score: 160.13\n",
      "Environment solved in 434 episodes!\tAverage Score: 160.13\n",
      "Episode 535\tAverage Score: 160.58\n",
      "Environment solved in 435 episodes!\tAverage Score: 160.58\n",
      "Episode 537\tAverage Score: 162.24\n",
      "Environment solved in 437 episodes!\tAverage Score: 162.24\n",
      "Episode 538\tAverage Score: 165.56\n",
      "Environment solved in 438 episodes!\tAverage Score: 165.56\n",
      "Episode 539\tAverage Score: 166.15\n",
      "Environment solved in 439 episodes!\tAverage Score: 166.15\n",
      "Episode 540\tAverage Score: 166.76\n",
      "Environment solved in 440 episodes!\tAverage Score: 166.76\n",
      "Episode 541\tAverage Score: 169.56\n",
      "Environment solved in 441 episodes!\tAverage Score: 169.56\n",
      "Episode 544\tAverage Score: 171.89\n",
      "Environment solved in 444 episodes!\tAverage Score: 171.89\n",
      "Episode 550\tAverage Score: 170.32\n",
      "Episode 552\tAverage Score: 172.54\n",
      "Environment solved in 452 episodes!\tAverage Score: 172.54\n",
      "Episode 555\tAverage Score: 172.90\n",
      "Environment solved in 455 episodes!\tAverage Score: 172.90\n",
      "Episode 556\tAverage Score: 173.26\n",
      "Environment solved in 456 episodes!\tAverage Score: 173.26\n",
      "Episode 557\tAverage Score: 173.83\n",
      "Environment solved in 457 episodes!\tAverage Score: 173.83\n",
      "Episode 558\tAverage Score: 174.86\n",
      "Environment solved in 458 episodes!\tAverage Score: 174.86\n",
      "Episode 559\tAverage Score: 175.44\n",
      "Environment solved in 459 episodes!\tAverage Score: 175.44\n",
      "Episode 560\tAverage Score: 175.89\n",
      "Environment solved in 460 episodes!\tAverage Score: 175.89\n",
      "Episode 561\tAverage Score: 175.92\n",
      "Environment solved in 461 episodes!\tAverage Score: 175.92\n",
      "Episode 562\tAverage Score: 178.12\n",
      "Environment solved in 462 episodes!\tAverage Score: 178.12\n",
      "Episode 563\tAverage Score: 179.21\n",
      "Environment solved in 463 episodes!\tAverage Score: 179.21\n",
      "Episode 564\tAverage Score: 180.11\n",
      "Environment solved in 464 episodes!\tAverage Score: 180.11\n",
      "Episode 598\tAverage Score: 180.45\n",
      "Environment solved in 498 episodes!\tAverage Score: 180.45\n",
      "Episode 599\tAverage Score: 180.88\n",
      "Environment solved in 499 episodes!\tAverage Score: 180.88\n",
      "Episode 600\tAverage Score: 181.12\n",
      "\n",
      "Environment solved in 500 episodes!\tAverage Score: 181.12\n",
      "Episode 603\tAverage Score: 181.41\n",
      "Environment solved in 503 episodes!\tAverage Score: 181.41\n",
      "Episode 604\tAverage Score: 181.92\n",
      "Environment solved in 504 episodes!\tAverage Score: 181.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 605\tAverage Score: 182.89\n",
      "Environment solved in 505 episodes!\tAverage Score: 182.89\n",
      "Episode 606\tAverage Score: 183.18\n",
      "Environment solved in 506 episodes!\tAverage Score: 183.18\n",
      "Episode 607\tAverage Score: 184.23\n",
      "Environment solved in 507 episodes!\tAverage Score: 184.23\n",
      "Episode 608\tAverage Score: 184.78\n",
      "Environment solved in 508 episodes!\tAverage Score: 184.78\n",
      "Episode 611\tAverage Score: 184.99\n",
      "Environment solved in 511 episodes!\tAverage Score: 184.99\n",
      "Episode 616\tAverage Score: 185.41\n",
      "Environment solved in 516 episodes!\tAverage Score: 185.41\n",
      "Episode 618\tAverage Score: 188.74\n",
      "Environment solved in 518 episodes!\tAverage Score: 188.74\n",
      "Episode 619\tAverage Score: 189.39\n",
      "Environment solved in 519 episodes!\tAverage Score: 189.39\n",
      "Episode 620\tAverage Score: 189.48\n",
      "Environment solved in 520 episodes!\tAverage Score: 189.48\n",
      "Episode 623\tAverage Score: 191.47\n",
      "Environment solved in 523 episodes!\tAverage Score: 191.47\n",
      "Episode 625\tAverage Score: 191.56\n",
      "Environment solved in 525 episodes!\tAverage Score: 191.56\n",
      "Episode 627\tAverage Score: 191.60\n",
      "Environment solved in 527 episodes!\tAverage Score: 191.60\n",
      "Episode 632\tAverage Score: 191.63\n",
      "Environment solved in 532 episodes!\tAverage Score: 191.63\n",
      "Episode 633\tAverage Score: 192.78\n",
      "Environment solved in 533 episodes!\tAverage Score: 192.78\n",
      "Episode 634\tAverage Score: 192.79\n",
      "Environment solved in 534 episodes!\tAverage Score: 192.79\n",
      "Episode 635\tAverage Score: 193.87\n",
      "Environment solved in 535 episodes!\tAverage Score: 193.87\n",
      "Episode 636\tAverage Score: 195.83\n",
      "Environment solved in 536 episodes!\tAverage Score: 195.83\n",
      "Episode 641\tAverage Score: 196.85\n",
      "Environment solved in 541 episodes!\tAverage Score: 196.85\n",
      "Episode 642\tAverage Score: 197.14\n",
      "Environment solved in 542 episodes!\tAverage Score: 197.14\n",
      "Episode 643\tAverage Score: 199.10\n",
      "Environment solved in 543 episodes!\tAverage Score: 199.10\n",
      "Episode 644\tAverage Score: 199.35\n",
      "Environment solved in 544 episodes!\tAverage Score: 199.35\n",
      "Episode 650\tAverage Score: 197.09\n",
      "Episode 700\tAverage Score: 184.50\n",
      "Episode 750\tAverage Score: 194.79\n",
      "Episode 800\tAverage Score: 111.59\n"
     ]
    }
   ],
   "source": [
    "scores = []; score_window = deque(maxlen = PRINT_EVERY)                        \n",
    "eps = eps_start                    \n",
    "hold_mean = 0.0\n",
    "\n",
    "for i_episode in range(1, n_episodes+1):\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    for t in range(TMAX):\n",
    "        action = agent.act(state, eps)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        score += reward\n",
    "        if done:\n",
    "            break \n",
    "    eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "            \n",
    "    scores.append(score)    \n",
    "    score_window.append(score)\n",
    "    mean_score = np.mean(score_window)\n",
    "    \n",
    "    print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, mean_score), end=\"\")\n",
    "    if i_episode % PRINT_EVERY == 0:\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode,mean_score))\n",
    "    if mean_score >=hold_mean:\n",
    "        print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, mean_score))\n",
    "        torch.save(agent.online_net.state_dict(), 'checkpoint.pth')\n",
    "        hold_mean = mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEKCAYAAAA8QgPpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXecVNX5/z/PzHbaUhakd1AUpKzYFRUVxa8mxghq1CQaE0uM+X1T1Jh8Nfkaid/EVGM3ttgSS4xYgl2UjgpIF5De27J9Z87vj3vPnTN3zq1Td/d58+K1M7c+085znnpICAGGYRiGCUok3wIwDMMwrRNWIAzDMEwoWIEwDMMwoWAFwjAMw4SCFQjDMAwTClYgDMMwTChYgTAMwzChYAXCMAzDhIIVCMMwDBOKonwLkE169OghBg0alG8xGIZhWhWLFi3aLYSo8jquTSuQQYMGYeHChfkWg2EYplVBRF/6OY5dWAzDMEwoWIEwDMMwoWAFwjAMw4SCFQjDMAwTClYgDMMwTChYgTAMwzChYAXCMAzDhIIVCMO0A7YdqMfbK3bkWwymjcEKhGHaARf+9WNc9TgX1TKZhRUIw7QDth1oAAC0xOJ5lqR98PrSbRh080xs3FOXsu/tFTtw8f1zEI+LPEiWWViBMEw7ookVCN5avgNfv//jlAH8taXb8Obn2zNyj5c/3QIAWL7tQMq+6/6+GPM37EVji/6zuOXFpfjLO2s879HQHMNtLy/FvtomAIAQAv/vuU/x8Re705A8GKxAGKYd0dzS+me96fK9pxZhwYZ9KQP4dX9fjO8+uSgj9xDW20yOx8RE8mexdX89hBB4Zv5G/PY/q5P2XfnofDwxZ0PStlc+24qn5m7Eb95YCQCoa4rhxU+24LKH56UpvX9YgTBMO6IxFsu3CDnlg9W7ELNZGi3m85Z49qwxeUshBC6672O8u3InYnGBobe+Ziku1Z24dmcNTpjxDh7+cH1CTmX/+6t34Rf/+jzpHhEylFOTeb2DDc3mPTP/epxgBcIwNt5Yth2fbtqfbzEySsScCDc5uE3aIu+s3IErHp2Phz5ch4bmGLabcSCJXbH4ZfO+Ojy3YKPHUca1D9Q3Y+GX+3D1EwuxaW9d0j1b4gLbDtTjkdnrsWlvPQBg9tqE+8lJvFhcoKahGUXmh/ryp1uw+1AjDtQ3h3o96cAKhGFsfO+pRfjKvR/lW4yMYp+tutESi2PPocaMy7Bi20FMe2AO6ppaQp2/ZPN+LNuSGlNw4kszgL11fz2ufWoRjrvr7aT9zbFwCmTaA3Px0xeWoqHZ2ZqTVoC0NmJxgUdmr086piUm8K2/LcCvXl2OnTWGcosr5kPcwZS4c+YKjL79P9b+uAC+++QiHKhjBcIwBcWz8zdi0M0zcagx3KBXKETM2aqfIPqtLy3FhP99C40t6bu7Vm2vgTAHul+/tgLz1u/FvHV7HY//89trsHzrQe2+8//yEc7782y8u2qn4zEqd/x7OQCgvDiKd1ftAoCk1yRdWE/O/RJb99cnnfvs/I24//0vkra9sGgzxv9qFraYxzY2J95LIQTeWbnDUipycFeVzJNzk5fYaI7Fsf2goThKiiLmdRL7nVxR/16yFQCwducha9v2Aw042JD77ygrEIZx4YEP1gEAdhxs8DiysIl6WCDxuMC9767FoJtn4vmFmwGEd/FI5q7bg7P/8AGemme4e7pWlAAA9tUZWUPSrSSziGJxgd/NWo2v/DXZ+lu9owajb3/Tev6tvy3AuX/60PXequylxVHrcW2jokBiAnsONeLnLy/Dt/62IOn8m19cihmvr0za9t//+Ax7TVkBQxldcO9HuOHpxZi1fAe+/dhC/O2jDQCkAwu4y3YNlZa4QJ0pz9PmeySQkFs+FjZNUlleDAD463sJBVccJRzMgwurTa9IyDDpIn+8zrk0rQOvGMjHX+zB/725KmmbHIM/27QfF9z7Ed770SQM6tHB9T7rdh3CxQ/MwUvXnYg15gx5xTbDWuhaYQx8+0xXy+E/f8M6b8OMqWg2rSO7jE/P24gazey6sSWGhuY4upgDqooaDygrjiBCxuupVSzJjXvrLGW2S3HZPfhBsuXhRGNLHJ9t2o/PNu23ZDD1tK9AdkssblmECzbsAwCocX35/qvxOCGEpYhVohGy3r9cwhYIw7ggxwGiwlchm/bWYdPe1MI1QHFhOSgQnbtKzuJfXGxYJO+t2gkAuOXFJXjso/UpxwPAI7PXY/ehJsxavsO6V0nUGGa6mAPf/romrXXjNADKYLGdb/1tAY6+4z8AgJqGZlz60FzMXbcHQMLKAQACIWpeo1aJv1z28Dzc8PQnAJBkWfz6tYTV4Fbsp75ndU3G42LztTrFL1RaNNeeY8oPGMpi96FGfPWvH1vb7nv/C3QuT533t8SFY9A9m+RNgRBRfyJ6l4hWENHnRPQDc3s3IppFRGvMv13N7UREfyKitUS0hIjG50t2pv0gx4HCVx/AyXe/i5Pvfle7Tw6gd72+Euf/ZXbKft3gIwdP+65n5m/C7WZ8wc66XbUAgL5dy60BttTy7xtXqm2MaWNKLUpQe9byRN+uoqh+mPr4i8Rg++bnO/DxF3sw/cG52LK/PinO8vaKHVbAvDZgLMsts0m6+oCEsnULrNtp8QjixwWwYXdt0rbZa/RFgl/uqcMnG/elyJNt8mmBtAD4byHEEQCOA3A9EY0CcDOAt4UQwwG8bT4HgHMADDf/XwPgvtyLzLRFth9owPQH51i+eBXphy4kA+SzTftx28tLrQF56/56rNlR43qOjIEs3XIASzanZjLpZsz2QjcnpaEiB1whhFW0KAPEMiOppqEZNQ3JA/NrS7fhn4sSA/J3nkj07SqOpr75dreVGgRfunk/bn1pqfV84ZeJgVWNgfhhj1LlbedBMz4GJBTH5n11mP7gHOw86J3F1uxRhyKEwEX3z0na1tAcc1QOqkINm+kWlLzFQIQQ2wBsMx/XENEKAH0BXABgknnY4wDeA/BTc/sTwvgk5xJRJRH1Nq/DMKF5ZPY6zF23F/9YtAnXnDJUewwVkA1y6UNzUdsUw83nHAEhBE6Y8Y7nOXYXnBAC++qa0a2D4Va6c+aKlHPkQKWOnV4zeHmbNTsO4fdvGdXUJdEI3lq+wxpwaxpaUiyQ6/6+2PGaEZvso/t2wSpFYa7eUZMUQHZTEkEtkN2HGjH5nvc9j/uPaTE9M3+T72t7WSA6L1hjS9zRVbVFUaJ1TTF0KkuNDWWagoiBENEgAOMAzAPQSyoF829P87C+ANRPZ7O5jWHSorTIyNJpaE6dEeayqjco3396Ma59ynngVbHHEZ5dsAnjfzULa3bUYH9dEzZqYie6me7MJcnztaWbD+D6vy+2qqblWH/PW4lWHEu2HMDVikVxsKFZGxTX8cpnW/H6suR7nnZ4z6RYzlm//wAPKzUWezWWpGTeeucUYh1OMaVM4NXYUuc+MxSI95cyqKIMS94VCBF1BPACgJuEEG7J3bopYMo7SUTXENFCIlq4a9euTInJtGHKiqWLJXXmasVA8myACCHQEovjHws3odYM2L67aldS5bIb8jVKZIxh4946HHPnW9pzLAtE+Zn95IUl1uP9dU247ulFmLl0mzX7lZZah5KEc0ONZwCGBWJ3Yeloaonjxmc+weodiXqHH589Eucf3dv1vOcXOlsBj328wfO+KvZBfGSvTjiid+dA1xjbv1K7fdsB99TwSb99L2VbY4uzC0tlw55az2MyQV4VCBEVw1AefxdCvGhu3kFEvc39vQHsNLdvBtBfOb0fgK32awohHhRCVAshqquqqrInPNNmkBbIoYYWfJaFFibxuMBHa3dr/eh+ufWlpRj2s9fx438u8T7YZNDNM3GzOeCXKbUQAFBvKqHy4qhjRbbXTHfyPe8jZp77wmKj+6xUtBUlUafTfFsguo60pUURDK3q6KrQZfrw3V8b43kPL3bZKvJ/feFo3HvpuEDX6NExNe0WAL4MYd00NMd9KZBvP7YQH6zO/gQ6n1lYBOARACuEEPcou14BcKX5+EoA/1K2X2FmYx0H4ADHP5hMIGfnj8/5EhfYWpikM+hLHp+zAZc9PA9vfh5+RcAgvnWVZxcY50VtLqx6M+hbWuw80OtiICq7DzVZqah/ensNahqaLTfBzhrnIPLGvXXYvK/ecb9EVo+rtMQFiAgjenbyPH/S4elPIHfXJLvDBnavcH3PdJSX6EPNe2uDt4tpbI5p03913DNrtfdBaZJPC+REAJcDOJ2IPjX/nwtgBoAziWgNgDPN5wDwGoB1ANYCeAjAdXmQmWmDSAtEh/yppqNH1pupmPmsZrfPWmXWkF2xqKzf7e4G6d6hJMlKOe/Ps335+oTwF4uQbpibzzkcZ43qZWwzZXroimpcMrG/47kA0LmsGD+ZMtLzPgBw7OBueOY7x2Hi4G5J219YvDnpefcOJSh2eM8umThAu93pLd5zyDlW40RDS9yzn1nfynLX+2aSvCkQIcRsIQQJIcYIIcaa/18TQuwRQpwhhBhu/t1rHi+EENcLIYYKIUYLIXh9TiYjlBY7/wzk+ChSw22+kYN3JBe/aNs9JfZZq8yCcnNTXfX4QjQ0x1Je+WGdy3DpsQOwp7YJu5VB8Ms9db5z1fy4V6Sba/yArrj9/CMBAOeN6QMAGNC9AscP7eF6fllxFNeeOhQ3nj7M8153XTgaxw/tjgkDuzoes/6uc41sNocXed2koXj4iuqU7QRg2R1np2x/fVnwxauaWuKeFecy7dmevZYNuJUJ0+5xqzKXiiOduiw5SEdzGIlXB5nZa3Zjv61TqxycvZZVVduNSGobW1Du4MbJxkssLYqgT2U5NsyYmrTdj3uRiPD/zhqJPpXlGHlYp6SqbhVZq+L2GcnviTowf/fUIXjgfSM9ORIhTDYtJQAY3rMj1uw8BCJCx9LMDbVeFoishs+FAsl7FhbD5Bu3gciyQDTHHKhr9tV/yLJAlN/zrppG3PrS0qysz1HfFMPnWxPFgt94ZB5224LB0gLx609XuerkwY4K5JONzkkIt009Aq9+/6TA93OyEIO4FadPHIBxA5ytC6lA/FiJ6sCsKhyZKn3fZePx8vUn4nun6muK0sWrAFEqkFzMV1iBMO2STXvr8MUuI1vHzY0jbH8lzbE4jv7lf/Czl4yKcNkwUIcco9XB6Rf/Woan523EOyt3OpwVnssenouv3TfH9Rip1IJWLK+/61zcNHkEyl2yrJwoilBKNpjksM5lSc/VGbtTjEqXjWRPV/ZLZ7Pozo+XUT0kSZmYJ58zujfG9q+0vlf2SzpZI1KJeeG1kGIuXVisQJh2ycl3v4szfmdUGPtpYmrXMTLd98M1u/GPhZtxzh8/xLur9MogblkgiR+0bL5Xqhk09hxqxDsrw2dsLXaxAuw0BVwjXbpxdHLr+OHkEUnPSzR9ra44fiDm3npG0sCqtipxupccoC8cl6gnXvmrc3zJpfLidSdYis2Pm1H9HNVJgb1Y02lZ9GV3nI0NM6Ziw4yp+IuSEvznS/ylB3u57iwXVg5Gd1YgTLvH1QJxcGHJhYAGde+A5ab1sX6XPmtJ9pRSx84GK4029Sd4/dOL8e3HFmJ/XfAsHSfOG9MbPzprRMr2sC3A7TEVJ34weTgW//xMXDiuL75e3R9Fmr5Wkk5lCQWStJ6HgwIRNstuRK+OvmQCgGevOc56PF5xbTm5sH4/7ejEE+WQqIMyMQSUh7vEVZR9fu0FL69jLmMgHERn2j3uMzp9R1o1O8taM8Th9xrTWCANZuxD59KRmU07DjaiUrP2QxjOHd1b2xY9rALZ49IuxE63DiW4Z9pYAMnt1CXyvexUVoRtZuhmf33i+k51F2cd2QuPfdwZ100aih+dNRIdTQX00BXVKS4xO1JZ2Yv81M9o4uBuWLntIA42tCRVn6tvo/o41QLxbsRJSdfyN+B7FXhKJZ2LJQhYgTDtHrcZXcICsZ+TepLTz9WaKSs/6EbTAtEN6j07lWLtzkPYWdOAkYd5F8z5oSQa0bo0wiqQ758+DM/M35i07ewje3kWS+pcWJIpR/XG6h1rTLm8LZDKihK89oOTU7afqWRCOdGxtAh/v/pYDKlKXiBLFa8lFrdayRcrO8jB6rDX1PTuYtRjDOtpWEbzbj0jRZmop/gd7/1aIC7GXsZgFxbT7vETRLcfoyoWr0WnrDReZbSQLizdrXt2KgVgWCCZorQ4op3hOrUx8aJPZTlumjwcAHB0vy7o3qEEXx3Xz/M83doecqZ+0xnD8ZWxRp3H1ScPTpyThfqZDqVFOHFYD2uQl6jvUSwurM9MVXyqONGkGEjyaztlRBWe+c5xuObkIQCAXp3L0LOT3TJSlFGGLBApEwfRGSYHuFsg+nYeifWqEz9obxdWYptsJSJgZEKp9RgygCwbDt4503sdDi9Ki6IpAxwA/FnTb8ovcoAa2rMjFv38TAzqUeF5jpsyiEQIN54xHCXRCKZVJ6rMs+GKccqEUgfdU0dUWTEO1dKgpEEf2seS44d2d00NTtrl2wLxcGFFcufCYgXCtHv8FKTZK9F1nVSdfq7yB58UAzFbx9c1tWDUL97EjDcSy6hKn399cwy7ahrx0IfrkS6lRRFt25IgVs45Rx2W9Ny6nvnWlJnptp3LivDnS8bhN18bnXKNYhcXFgAMqeqI1XeegyFVHXH+0X18yxYUJ7eYfE1njuqFH0weYT1XFbxT3CLMgJ3kDvNrgXj4sBIWSGBxAsMKhGn3uP0g1V5Y1z+9GD949hPsPNiAu99YZe4XngVt2iC6aYEcMivC1dX45AyyvikWaIlUN0ocFIiOP2nSSf/zw1Nw3zcmJG2zD3gyoywWF/ivo/tg2jGpvaF0Mji9f3+cPhbrfn2uL5mD4jTYy82HdS5DNEK45+KjMXFwNxzWpSzlGCB9N1EIA8Tz+1bELiyGyR1+g+gzl2zDvz7dmtT/SY2BOPmwdNeXFeAJBZU4SD7afagRa3ceQiZwskB0DKtKpMMO6WEEmXWDkXU586+0QMJUt+sgooz3D/Nay0NOJuTLPXZIdzz/3eOTLCdd8WBYVK9i5mIguasD4Swspl3x4ZpdWLU9ef1wtx+k3FfvYAmoZ3q5sPwE69Xjnpm/KVAb9+OHdMecdXu0+/xYIFedNBjfPGGQVeQ4sHsFhvbsiHW7a7Xre9hdWKoFEoTMqBt/vHTdCWjUrDwZhKRK9DQVSFIdSIaysHIZA2EFwrQrLn9kfso2Pz2VLn5A3xpECG8XllQIusO0acIhRtSSaASPffsYjLwttfkhYLS/8Mpm6t+1HP27VWDtTkPBRshw4Sz6ch/6VJanHJ/iwjItEJlFVoiUFUcd26kAibfezRpIqkRPc4xWb+N3vI95WSDcjZdhcofrD9JjMFdVg1cWVpKbymaVqNaJnzWv7XQuL3LsGTW0qgP6dyvHyu3B+l4RAZ3KijFpZE/tfrsLKxoh/H7a0age2E17fGvAz1uvfs7pdlhWrQS3inUVr6SPohwG0VmBMO0ev64liTpmCKGsm+4wAMjmd7rbWO4eZV+GQggWt00dBSLy7a+3mj96DI666/mpBbGTgUUfM4YfUcJkTjley7qm/wHf6/vBdSAMk0NcDRCP0U0o5ztaIJaVkdgmB6GYLZhuHBd8RH3g8tSFjCTST++lQOxFk16z61z42HON/Lz9Dr7pxkDkfQj+30//dSBpieYLViBMu8dPGq8fvILoulUNW7TurQA3BXD/Nya4rqQnFYEaA3n66mMdj5cWk9cAFDYDKXXp1wIyQUz8Dr4eZS2B7uP37fT6flhZWGyBMEz28ZPG63aA13K3UkHp7qPb56ewUaVXZ/egtd2lURKNuPbYkmtq9O/mXlke1v9/9pHevaryRVDlnbYLi+RfypjFwDEQhskhYVxGiXO9XVhWmENznxZLgYiU4/3iN1Yhu7QKCFfrYUhVR9x76XicPMJ9zfGwA55d3kKKgTgtAuVE+jGQ4C4sL+Rn6zconw6sQJh2j+uSthrrwul37vSDTWRhafZpUnyDKjQvV5J0s0iLQQhv3/3UMb0DyRCEdIvvcoF/Fxbhn987PlB7e919iPwrLS+kBeJlGWfkXlm/A8MUOOm4sLwdWMnHptw7A1lYXrNguT9qDSyZ9Y8HnenmwjcfFvnW+7UGIgRUDwqftpwIolPG3hdZB5LpbD4dHANh2j1+ViR02iZ8uLDkdt1a1omWJqk1In7xallhubDMA4UQ2vhFWFdS0Jmu3QIpJBdWIiXbH5mKgdgfp4O0QNJxzfqFFQjT7gk6U0tRIFYhob802aR7a9xbQX/3XsFsK4geSciRiz5JThSyB8tShj5lTFeBqMWYGbNArIlCRi7nCisQpt0TNAayZmeNsh96zaBgWSAuQfR0YiBe8YxUCyT9CmqVwC4sh6VfCwHd6pFupB/Pybw2ZQuEYbKEblwI6sL6wbOfKvsTw5/nUKBL49W2MvG6UDKeWVi2GIjunJKiCC4YG2z9jbDDUyaVV7bw7cJKt5miDKIjkxYIx0CYdsy6XcZ64NlA11Aw5LLgKeh+/3PX7bFiHzpFpcvQChoD8RqQdZXo9oHv3zechO4dc9MEsZCD6HLpWqe+YnbSNUCsIDq1zhgIZ2ExBcfpv3sf0QjhiywsJlQUiaA5ltyaPWgvrKT9wnnA/2jtblz28DzXa+nWzgjuwnLfby3Lag5Q3z5xcOoxIaaSYcc7KW9RhNASF5hiW+kwn1x+/EDsq2vCNacM8XV82s0UlceZtkCCTkTCwAqEKUiCrinhF91v1O2H5mcwT6R+Jm/fcTDZitJdS9dGJVuFhESE9XfplXKYwSvsJyRjJsN6dsQbN50S8irZoaw4ip9MOdz38ekW/6lpvBmzQGQab4YsazfYhcW0K3S/0XR01c6aBsduvH7SVXUWSFBxvAsJE/uNlhmpx+eyuK+Qgubpku77lpTGm6YsEqmUOIjOtDvcGhumQ1OL83QsaBBdZV9dM175bCuAVAvEPlDrLB2tVRLwh5+JpodhLJC0848KOBbil3SbKUqMGEhm3g+ZbcdBdKbd0dCiXzo2Hd5fvQsjbnsdn27arx0os/VDswfsdbfRuer8+K7VBoqeQfQsDdRtx44IT+ZcWJkLoucyBsIKhCkoahudFciB+mY8M39j4B/Ge6t2AgAWbtirnTZn6odmH0zsA7fOutIpkKC+a52F8Y3jEi3TvZayBQqrGrw1kf6KhInHmU/jZQXCtDPqmpyXXb31xaW45cWl+GzzgVDXJtKXvGXrh2Yft/VZWKnaIrgLK/VV3TZ1VEIOPwokh/ZEW1JW6cZAEmm8meudK91q7MJi2h1uFsiumkYAQENzZt1cmfqh2QcA++Ciu4+uBiUTQXR1NputGIgk7KmtPwKSvtspGxaInFDkQk+zAmEKCmmBZDIpSJ3x6mbruTD1DTm803h3HmwIrCB1bhT1/fNys9xx/pGei0e5EXYRppKi1j/8pJ2FpfzNVAxEvr9cB8K0O5pjxpe+SJPeYjUtDHlt3Y907c6ajGV+2a9tj2+4rQdi7BeY+Ou3074vkDyb9So0vPKEQYHvmQ5H9O6EG04bhkuOtS9t2/pIvxuvmmKdrjQGUqdxJTrTKvl86wG8uHgLbpt6ROAsFTnous2a08l8sZ85+Z4PQl8r9drG1Zta4vjOEwtxZJ/OSfvVOIOUQ1UyupoQP+hmwepbVJSl1rsjehnL4h47ONh6GESEH509Mhsi5ZyM1YFkMI3XqgPhQsJUiGgKEa0iorVEdHO+5WnNxOIC97//BQ41OgeuwzD9gbl4ZPZ61AS47udbD+Cv761Fs/mt1/0u5YRqV00jPlq729r+4Adf4Ms9tY7XlqZ8tssOpIJYu/MQ3l+9C39974uk/Unrnpt/VaXRHLIpl07ZqoNRtmoEx/avxJxbTsfXq/tl5watAD8Zbm6oabxBLqWmcduRH30uEiNalQIhoiiAewGcA2AUgEuIaJT7WYwTr3y2BTNeX4k/v70mo9eVbpkgP62pf5qNu99YhZjpwrJnDsXiAgu/3AcAuP7pxbjs4XmobWzB3tom/Pq1lbj8kfme9zBcWP6lWrxxn/8XgISCc/rh6jwK8SQFEu4H7/WSslmw17tLeZsoCAxLpmIgxmP/1/rZVOdhL1GJHlYq/7QqBQJgIoC1Qoh1QogmAM8CuCDPMoVGCIGXP9mCxiwUz/lh636jV1OmBwCrRXmICfW63YcApPqWP/5id8qxLTGBFnPWXtekfw8bW2J4fM6X1vMgr/TCv34c4GigvikWuK9WLKQForqlwn5+L153Av7nv3j+lQ7pugfVNN4guqi82LlbcC6D6K1NgfQFsEl5vtnc1ip5d9VO3PTcp7jnP6vzcv+9tU0AgO4dSjJ6XTkm6mocvPj1aysBJJvzLbE4Xlq8RXMfYd3L6cdX05DsRsvmZPknLyzB0/M3BjpHDaK3BLBAhlR1CHQfHeMHdMW3NJ15Gf9kshdWkNmN220TQfRQIgWitSkQ3duW9DYR0TVEtJCIFu7atStHYqWyfnctLrj3Ixyob3Y8Ru6zd23NFftMBdKlojij15Uzn3Q66qo/zIdnr8eLn6QqkJgQ1qw9QoRYXGDjnjqbLInHxkw9u+6W15Zuc0xrVd1VUorZaxKWVRAL5LwxvcOIx2SYTDWhJAqW0eV2LFkuLLZA7GwG0F953g/AVvUAIcSDQohqIUR1VVVVToVT+dPba/DZpv14a/mOvMngxUFzdp7pITVhgYT/Aqtume0H9Aq2JSbQFEsE3Z+evxGn/N+7+ESJXdh/RNl213+0dg/O+/Ns7T7du1Gv1Hw0BVAg045p/SmwbYG0K9Flq30E+x26fY9zaYG0tjTeBQCGE9FgAFsATAdwaX5F0iOzM/y4cfLV2UG3nGomr5uWBaL8Qpzka4nHExZIhKxK9VeXbMO4AV0BpM7q8xnu9XqfazOcDff6D07G8q0HM3pNJpl0s7DUs4NYIG6Ki2MgDgghWgDcAOBNACsAPC+E+Dy/UumRi7qkMwvPNnKAD5M9Wu8QtAYSbiOn117T0IxBN8/E8ws3afcDyT8Qp99BS0ygucVk42TVAAAgAElEQVTM2iJC5zJjPqS2blfjCvlOFkpatlazX8akMsURvTvjaxPab4ptLshoL6xAMRDngwd1N+JjVx4/KB3R/MmR9TtkGCHEa0KIEUKIoUKIO/MtjxMyOyNIYNTOq0u24gfPfpIpkVKwLIWAM5VV22twxC/ewL8+TY1LqMQcrC9pKfxhlnPygPr7cLZABJrM5WkjBDSaikP9UasWSCbbRYThj2+vwWtLtznu31+XiJf5mdm+fP2JuOP8IzMiGxOOtC0QUh/7v5bu0OIooUt5MbpUFGPDjKk5mTy0OgXSWpAWSNjiMAC44elP8K9Pt3ofGJJEum0wBfLiJ5sBACu21bgep1ogW/bX42CDMUA2NBvvyX6XBIMkC8Tx+nE0KRaI7CGl/rjstRWZ63kajpfMZACdFDc996n1+IRhPbBhxlTXa43tX5nzNiRMMvnqhVWq6SO27I6zseBnk9OSJyisQLJEsdnLyc2Fle/BTBoIQWIVDc0x7DnkL/1Xtb5OnPEOzrrnA2zeV2dVvsvaDd2sXDXRnXy5LbFEFhYpFoh6X3sMKt9urA4lzvn7KjlcYZZJg7RrqEheJ1gMpCSa+B6NNFvKlBZFc96gkhVIlpAzEz+Dc77WRwgT7L7o/o/xz0WbredugTr7dbcfbMBJv3k3pe3Igg17U85Vf0uOMZC4sOIdESI0mhaIqjResVlw+V6LoqLUX94K64/2h9Nn/uuvjk7ZpiqKmTeehDV3npMlqdxhBZIliiPeLqx8z4bDxECWbUlk9dz52goMvuU1CCGw6MtUJbB6Rw3e/Hw7Ln5gTtL2LfvrAahLb6beZ92uWgy6eSY27K51jIHElCysNTsPWa4x1W318Oz11uO4yO3CSTr8WyCsQtoX5PiZ69ZdVxVIUTRieTxyTWtL4201yHbk6aSySuJx4WtVucDXNUVLV8bnF27CT19YivsuG49zRicK3H78zyXa42UBo86Pa2fSb99Dv67l2n3NSh0IAPzrMyO+0OKgtONC5N0CKS/xaYGwAmkfJBW66g/RuboLZS2VwpCiDRK16kB8uLA89gfNkvLDsi0HsMhsTiiD6I99tB6PfbTe7TQtm/YaFsWanYd8Hb/XzDYqLYoY9/x4g+vxm/fVa7fH4iLJ2rAsEIf3PBYXOSmucsOvWrDPF3527hEZl4XJP/LrSJRQICmKRPOlKYlGcO2koeia4S4SQWELJEtYhYRpZGFJYnEBl95poVCrpaWCuv3fywEA3wzYH6ncdMs4NTS0s2yLsaZ5aVEUf/NQHm40x+JJNR8S+Z7b33vDAsmsBolGKJAF1xyLo6ah2XNiYX8v+1TqrTA7r37/JGzaW+d9IFNQGJXo+umFzrVVUhTBT6ccjp9OOTzLkrnDFkiWkC4sPy26hZJOq2vbkSk32J/eXoPdhxq1+9KhzNRu9U3+KqnX7zaC6C1xkVadTCwurCVwVeQ17euc/Pq1ldiT4WK9oJ7F5lgco2//j+dxs9cmdx/269E6qm+XJDciU9gIXy6sVPy4f3NBYUjRBpEDi1srE7uf+/4PvsBxd72NhRv2WjUTQKoL64td/lxFKmt3HcI9s1bju08uStnnx0XWEos7NoaUBYP1zTHfdS89O5WiJR5Pq41Kc0xgo2a2LV1Y9k682SBorCL0mh+hzmIKna4dDBfUj84a6fgZ675iJXkKmtspDCnaICJEgFqusnfR/XNw8m/etbbHlEHn3VU7ccbv3sfLmu60dppa4vjlv5djX22TlaUh4x4qfuI0Nz33KY6+Qz9zli3Y65vjuPShuZ7XAoBencvMOo70LBBpzagsWL8X63fXJinhbBHUAnFrAeMGx9TbJqVFUWyYMRUXH9PfiptefVKyC1nnwspGUk0YWIFkCTmzdhsgpevKCqQpcxB1tq9aCGt3GNbHUjOOcNOzn+B/X12uvf7MpVvx6EfrcfebK90XOvKhQF5d4tyCQ1Lf1IIFG/yt4ldeEkVzLO7Y7sQPLfE4dh5MdcnVN8dw2m/fy4kF4rZ2OwBMGNg16bnOheiPwhgwmOxBRNgwY2rKaoOFPHlgBZIlrOVNXcZmv63GVStGHiPPffnTrVatw1Nzv8RTcxOr78msJK/soyBx/uKo87dZbU2uo6NSRFdhKZBUwQZ1r/AlS0tMpMQ5KpQ6i4MurVKcOHNUL/T1GbAGvOs1Kmx1Hztq9K3pv3nCIDx11bHWc/UxUNiDCNN+YQWSJeKWdeFWqW0+sFbV048SqovJrfjutpeX4baXl6WcF41E4JYs/OhH67VWyBNzNuBr9yUv65pO759Lj02sYVFREkVcpFpoPTuV4phB3XxdryUeTwmiVyvnhrFAfjplJIb17Oj7+EZNFpiKfenRHRqLCQCunTQUJw3vYT0f3a9L0n7WH+0X+7iQbgPHTMIKJEtY43EAC8Tpe6EO7vLL5Ce2ItNYi6PkWf8wU+lHNX+9UVX+i399nhIzKXZZA9qrt5c6mJYXG9aIfT34aMS5ItdOc0ygtjH5fDW4uD3ESo/RSMR3nOKqkwZ7LgJlL/iSnYi9cFvzmmlf2MeJQikiBFiBZA0/izXZZ/1+LBAZPPOTOSVdWEWRiGcF9vefSbSNv/iBOY5t5ItcXFj21FM7qjtHPrYrtmiE4KKjkvjLO2tTBnA1phKmHiJKhLpmw3L5v4vGYNkdZzsee9Pk4Z7X8/tjt08IpKvww5+chvm3nsGV6e0M9eO2T2gKaXLBhYQZYs+hRpSXRFFhtqrwE5iWhwgIrNh2EG+v3Kk9Th1cZNDWT0FcjZmFJCACp8s6tZGP+h3dNZRrFEjq9cn3YKmzMFSFsmlfHcqKI5Yi9UM0SqgzrZpxA7qizEUB+LGU/KZb2hWIfA/6dzPiQYQDvq7D5IYXrj1BW8SaKSqKo6g1FYc9tlhWQAqELZAMsP1AAyb871u44C8fWdsSysEZ1Yo4548fpuyX41MsyYWV2Kb6/5+ZvzHlfFnNXN8Uy1gPqPBZRDYXlpMCIXJNjX3yqokp2371laOsx+qP+oudtehWUYIXrzvBt4xRItSa72uH0iiKohHHGZ8fBSJjPAO7V+CByyck7bu4uh+qzSwtr0uxAVJYTBjYFccP7Z6166u/D3tXAqffTj5gBZIBjrvrbQDJvaASLizn86SV4tXCIKaJgcQFcMlD86ztt7y4NOV8eV5dUyytgr2Pv3B3TfmloiQ5C0uH17oIuiC+au2ps7PtBxtQ1akU4wd0TTnH7fpj+lUCADqXGUVevTqXao/16uz7m6+NttJ4KytKcOqIqqT9zTGB+74xATMuHI1+XQ1L4+ZzDsfJSjBdwgqkfaEqiUJ2YbECyRJqexInvDK1IhoLRE3j/WzTflcZ5PX99qhy4lJFUaVDeUlEeaz3nhK5B9GLbC60kmgEU8ckWnfYZ4VVncoCyRiNEP4wbSxeu/FkdDDTjiscZC0rcv4hF0cJ044ZkGRNlRVHcf83xuO7pw4BYLQ1qepUiukTE9lp3zt1KJ60pfAC+V98jMktFcWJ75zdhZXOZDDTcAwkS+hapb/5+XZEiHDmqF4p+3QYfnCR1A4lYsVA/MhgHJRuy5BMoQ7+FSFnUZ3Kkr+yd371KPToWIrfTzsaQ6s6YlTvzqgsL8Hry7bhwzW7UdUp2Xro06UMe2qbHNNvoxFCh9IijOrT2drWoTRV1ksm9netBpbKxVKG5vs/5aiEsgu03DHrj3aFaoHYv/O5KJD1i28LhIhOIqJvmY+riChYy9ZWTkssjp+/vAxb9+tbi6vUNbXg861G0FONc3z3yUX4zhMLredexYYRxdqQyOv5SeOVxxRCG3MgOYOrtDhccLp3l2SLQloHXx3XD2P6VaIoGsGlxw7AQLMYsW9l8vFDPWo8dC6yDppVBL3qYayaDs1hxQEabUrUy3w7YLdkpvUhXbxfGdsH100alrSvJgctevziS4EQ0f8A+CmAW8xNxQCeypZQhcKW/fWYvcbw/3/0xR48OfdLK9aw51AjfvPGSm279u8//QneXbULgPtA75WKKwdStWOtdIn5SeNVraBMtzEPg7pqmlMLEIJ7f6ku5cnrH6huMRVpAcgsJr/raeiKtDpoXFh2V5rK3ReNwZ8uGQcgMfCr736iU3PwLJ4B3Srw8/N4bZC2TqW5zsf5Y/ukpIIP6tEhHyJp8evC+iqAcQAWA4AQYisRdcqaVAXCOX/4AAcbWrBhxlRrvW2Zn3/904sxd91eTD6iV8p5H3+xx3osFYgaCFuwYS+6VpR4WhFSgby+bDuWbT2Iq04abNWE+FEIUtm0xAX+oaxjvmZHjee52UBVIG6pum6uIft5Ttf5/hnD0bVDCc41W5vL2Mjhh3XSrsFu3VtzPV3A380CGditwnqtuuvJ71CQNFD5OiPEqxW2B351wVHoW1mOU4YnJ148edVEjOrd2eGs3OPXhdUkjBFLAAARFY4KzCIHTV+jEImlU+VsYO46YxAq07hi1JiFdD8d8Ys3rG1fv38OJt/zvjWQr9yuH9DlOPHYxxvwq1eXIx4XVqsSXy4sJZD/9LxEmu/0B/11zM006nvlNP6qK7M5seT2s3CKmdHU6FDj0aW8GNefNswayI/q2wXPf/d4/GTK4a7xI50FMl5piCiVid2VpnKEEj9xa8UdxAJhldG+6N6xFD+bOsqyViUnD69C9476rMB84FeBPE9EDwCoJKLvAHgLwEPZE6uwaGyJWwNVqS3zxj4Y1TQ0J/m23RZMetks1tO1JAdSZ687lTYYfmIaMcUCSZYxEYQ7boi/vlOZQM1acotzeNVXdC4rxkUT+gEAhvfy37dq4uBuSVaQ9t4aBTL9mP64ZGJ/AMBXxvXFH6ePxbcc4hBLbj/LSv8F9EkPclDw00ZfkljulFUJUzj4cmEJIX5LRGcCOAhgJIBfCCFmZVWyAqKuKWZl7bz0yZakame7Anl+4eak5+msZ24fyzbtS7Tm8OPCclqTRJXfa0DVEXQZV0lZcRSv3HAi1u+udW1XIl/3kX06Y+X2Gu29zj+6D84a1StUVa5uDB7WsyPWOqzpTkQ4sk8XAJsAABeM7et4bXtsx0rCUqIgPc3MMHurd1eZTRuE1QdTSHgqECKKAnhTCDEZQLtRGoDhq26OCdQ3x5Ka/s1U1sawp8fal5qMpxHAts/Et+xLZIAFsUDcBvswCqSiOIqaxuCphGXFEYzpV4kx/SrxrkPbFjL/AcCo3p1xqLEFX+7R97TKZEuHm6ccjsmjUuNZkoQl4S9uJSGNBdKnshzv/PepVoDfD9ZlWYMwBYTn6CGEiAGoI6IuXse2NaTLpb6pxTHgucY2a7UrkJgSPwmK3V1Rq7QucVMK9kwtJxcZkNvW0OqA77j+MyVm6z07l6JXwELAsHi1+LJSqm0f5e+nHY2/XDrO8TpO7+6Qqo6BlDfrD6YQ8ZuF1QBgKRHNAmCNRkKIG7MiVYFQas6065pijgrkR//4LOUclVhcBGrmp2If2w8psQu3wsCYEIiArNmy20JPYSyQsKjK1S3Osb/OyHPv2akM9142HrOW78CtL6W2askkXrGFRAuZ5Pf9q+P6JWXY2V1YQQo/3QX0JyfTNjltZJVVGlBI+FUgM83/7QqZNVSvxEC8KLaN+rG4sFKAg2IfZO96fWXSdZ14e8UOPPDBuqRgrhNuKww6EXYsVAc/NwUi18yo6lSKqk6luPTYASiOEob3ykzmuHSR3XPx0bhn1mps3lfv3RjRKup0PyzVhRVWSlcxmHbG/ZdPKKgKdInfIPrjRFQCYIS5aZUQonDKIbOEdLnUNcd8u6HsmTWZtEDc7qNy/dOfIBYXOLp/pec9wlggmShKdHttsuOv2obk69X9076nHXXpWi9PnmVJaNSnqiTsWVzyafoGCKXci2k/lBZFUdqxcJooSnwpECKaBOBxABtgTIL6E9GVQogPsida/pEtLA7UNfu2Ilri9gWOBBpawlkgbu4KXQW8ek/A35ok9jzznOEYAyHsPtQEAOiR5Xx3dbD3skAsRRBYE2RmxLfSeNkGYQoIv6PH7wCcJYQ4VQhxCoCzAfw+e2IVBv26GjPUdbsO+XZh2fsbxYRAQ0gX1rYDzn23/PRR8lNnkEsXlorbgP2VcUaarFuxXiZQZfCa2bstJex2bkLxpPeuWUF01h9MAeE3BlIshFglnwghVhORt4O9lSPjGV/sqk3JrnLCXji4blct3lqhT1n1wm3891PF7MsCCbHCYNCxcMaFo1PkdVMgP5w8HDecNixraz/LW0dIfew+Mqtt9FP2uVgFmQp6c/CcKUT8/kIXEtEjRDTJ/P8QgEXZFKwQkONvXVOLbwvE7sICgBcXb9YcmR5+YjI6Wey4rXHuRpBV/s4c1QuXHz8oaZtjKxMYg2W2lAeQUIDRQC4sGQNJxY8Fki6sP5hCxK8Fci2A6wHcCOM3/gGAv2ZLqEJBXVUwrAsLyEAKp/Y+3vL4cXP5WZbVjoDwvda30z2cZtS5HChVuXwH0bUWiDOZej3yMmE+L4bJFn4VSBGAPwoh7gGs6vTC6eiVJYTyt9EhEB6hZFeTW3A7kzS3+IiB+JAlbCFhkHFMr0BC3TYj6NxW3nUgxl+dUed2rq4SPR1YfzCFhN9p5NsAypXn5TAaKrZp5GxTCOFogdgHR13gOhurAfpxTzX7iIG4tU53QohgM2HSfMsKYSYdjSTapni9DVIRBP0sM/UqE80UM3RBhskAfhVImRDC6tlhPvbfyMcGEf0fEa0koiVE9BIRVSr7biGitUS0iojOVrZPMbetJaKbw947CHKMjgvhWIluHwh1rqVsuLD8rCXhx83ltLCTGwLpWyA57KDiiCqD/yC6Zp/reRlTIRm6DsNkDr8KpJaIxssnRFQNwHttV2dmAThKCDEGwGqYKx0S0SgA0wEcCWAKgL8SUdR0md0L4BwAowBcYh6bVeKWBeIcA7GPDwfrU6tFndxfYbnmlCHWWiVu6FrJf/OEQUnPwwbRg9Qj6JSF04Cd0xhIiCC6LozuK403zeRnrgNhChG/MZCbAPyDiLbC+AX1ATAt7E2FEP9Rns4FcJH5+AIAzwohGgGsJ6K1ACaa+9YKIdYBABE9ax67PKwMfpCzzbhwbkdiHzxkFbXKgfrMFu37rd3QWSD27CYn68C7ZYcvERzv4dhMMQcDpC4g7V0HYvzV14G4xECQmRgI14EwhYirBUJExxDRYUKIBQAOB/AcgBYAbwBYnyEZvg3gdfNxX8hFFww2m9uctutkvoaIFhLRwl270m0+ZvzqaxpasGV/ssE1rKexkJG9Tcme2lQF4jYYf/fUIYGl8tt+RKdA7MoniHVgITIQRC+AmbTqvvNrgQRdBiVjrUzM++f/XWOYBF4j0QMAmszHxwO4FYYraR+AB91OJKK3iGiZ5v8FyjE/g6GQ/i43aS4lXLanbhTiQSFEtRCiuqqqSneIb+Rg8fnWgykuLKc01t01TdrtTlQP7Ga5lS6u7ocRPlbY86tAdIOdvXBQN256DXYCIpBvX6ukHF5CLmfY6vK5XvWU0tUXuHI/Q6/HSh9mE4QpILxcWFEhxF7z8TQADwohXgDwAhF96naiuQCVI0R0JYDzAJwhEsn1mwGoXfP6AdhqPnbanjXcMm5KNWuhA3oXlhtqGu3IwzqjsSWO1Tv0K+NJgtRg2LHXMegsAT9tN4IMY3o3Wf4HwiCFhCcM7YHvnjIEV508ONA9/C5E5YU8O//vGsMk8BqJokQklcwZAN5R9vmNn6RARFMA/BTA+UIIdbm5VwBMJ6JSIhoMYDiA+QAWABhORIPNrsDTzWOzipu7wmkQ31MbzAKJRChpUulngAjTv0piTzPWXcvTAhHBsot0h7pVoueKZAXifewt5x6BngEXuMrU65EKqAD0LsNYeCmQZwC8T0T/gpF19SEAENEwAAfSuO9fAHQCMIuIPiWi+wFACPE5gOdhBMffAHC9ECImhGgBcAOANwGsAPC8eWxWcZs1XjJxgOO+gd0rMOXIw/Dg5RN83ScRaBW+ZubFabT5sAeBO5cX44jenZO2CQH06FjieA2BYEF0nbLJZ28nK55Aqdsyjcz0SjcGYnmw0rwOw2QS15FICHEngP8G8BiAkxRXUwTA98PeVAgxTAjRXwgx1vz/PfWeQoihQoiRQojXle2vCSFGmPvuDHvvYHLqtz/zneNweO/kxY0++PFpOP3wngCAjqVFuP/yCRg/sKvnPWLxePKs0scIURygAeK5ow+z3S/1RZ02MjVW9OFPTsedXz3K8brpBsELYSBUg+jZkifT1+Wmikwh4emGEkLM1WxbnR1xCgunGEhxlFIshQHdK9CpzHg7y82FqPxYE7F4IigeodTrau9f5H8Q6VxWjLLiiJUtFrPHQEjvFikviaJDif7rIYRI25Xi+DpzOEBGiJT02Ozc17pumiYIx0CYQiRPqwm1DpwUiNECI5WO5gJU5SVSgXjfIxaP44bTh+Gqkwbj0mMHeJ7zyg0nBlpFMKK06wCATpplbv1aE1HFHZMtBZLLATJMG5egZEovZaObAcOkCysQBy5/ZB7mrtur3VccjWhnrB1NC0QuhetnVhuLG4rn5+eNQllx1NMCGdyjQyAFEqXkIP3XJ/TDN45Ljt843dJePT3rh6co56TpwiqAqbQqQyaW6dXh1gY+CBxEZwoRViAOfLhmt+O+oihpLYVOpgUifeu+LBCNS8mNokgkYCv15OfRCOHSiQMT9/Npf5wyogrdOiQC6+mOY7mY/fsh2zGFjGVhyeuxBmEKCFYgPlFTPosipP0hS/eQ7JTrJ54xum+XpOdeA0Q0QoFdWMnXhxWrSdqocHF1v6TnF4ztgye+PTGpNXm6dRz5HAZ7dipNkSFbHqJM1YFIdyqrD6aQCF3L0d4oiUZQHzf6YRVFIlpLobLCUCCy0aHXIPv+jydhYPcOSdu8JuZFEQpUB2Jf7yNChP7dytGtQwn2mjUr6iFTx/TGXReOAZCaOqoq0azFQHIwQj519bGYvWY3OpUVZ31AzvTrYQOEKSTYAvGJ2oQwGtE7fsb0M7rSr99dC8D7x15aFE3Z5uRQqjJnzZEIBaoDKYpGkq4oH580rIclo3rPkmgkSVGoqJvtR1QP7IrxAyph54KxfTyvpZKL8bFPZTkuPqa/94GFBAfRmQKELRCfqG6j4mhE26hwUPcK/NfRfTCt2hicvBRIh9JUBeI0sL58/YlYsmm/cf8AdSB2C0Rf1Jd4rKsTScimWiCJx4996xiM7V+Jqx9fmHKOU8Fle/HlZyyIbv4thCaUDCNhBeKTUpsFolsehIjw50vGWc/dXFjXTRqqT6nVnDP7p6ehb2U5+lYai0IG0B+GtaRpW64OaOodVQXSvaNh9fTvZqwd5tT+fNJIo4DS3irefm0VRwskx4pl3ICuWLe71kqAyDTW+51uHQj3UmQKEHZh+UQdHHWFhDrcjjl2SHftdt0p/bomL/4YZBZqD7hLmWT1+eGHdU66p7pU7inDe+ChK6px4xnDzXNVGVLpYSqc6oFdUWY2m3TKtioUC+TOrx6FmTeehJ6dg/W48kvCAkm3mSKn8TKFBysQn6iB66itAaITbgFxWa2eeo4PxRTQAlGRzy4c3w9Lbz8LIw/rlDSYq545IsKZo3olVcq7ySmzm8b0q7TiO4EtEJfXkg3KiqM4sk8X7wNDkvEgOruwmAKCFYhPki2QiK+B3m2W3blc7zLxUx4RZBApslXNq3LrXGhuLeylNdGva7l2YOzZ2VAgdU0tlsvP6T0oFAsk21gLSrELi2mDcAxEQ1wTSFaL9/xaIG501gzegL+BVWZk6Zg4qBvmb0hU0NuD6Drd4zeIDgAPX1GN0f26aJWYdGHtPtRkrZfi9HIKpI4wB2TmhbopdobJF2yBaGjyWEu8yCGNNwidy50UiPe53TqUYPIRPbX7+nUrT3pelBID0dxTeS1H909NxVWZPKoXenUuA2m+OV0rjEr1moZmy4XlZKnlsw4kl2TMAjH/thfLjWkdsALR0NisW0s88VYR6VuZBKFDiT4G4lcxOVkw9hTfIGm8EwZ2xQ/MgLkXOim7KIWU0mJzejWOzXjbmI8/UwP+sCpjqeMpRx7mcSTD5A52YWlQM5EkpbYU1fSbCXoX6wHA9IAFb0W2KvWiaASlxRHUNOqvDyQG+eE9OzoWEabKmXpcpWlVHaxvtuIhuvfS6fy2SKZcdf27VWDFL6dY2W0MUwjwt1FD946lVjGgxF7jEHZguPGM4fjplMMd99sH1hlfG6M9zskjYk/bLYoQvnfqUOu5boYvbxlkTNe3cjFcWAfrmy2Fq7PmXO/VxvRKJi2q8pIou7CYgoIViAP2VFn7wBx2YDh1RA9cO2mo4345Plx10mAsum1y4OunpO0ScPXJQ1Kur5JQWv5fk+71dzabNPbtWm7FQBp1FZdoPxZIopCQg+BM24MViAP2mZ69hboaRJYV4j6v7Ou+ncqKrEpwHU4Dkt2FlXp9D/F8ortOUTSCJ749EU9cNTFhgbTEtOe3NwXCMG0RViAO2H/3dheWuv+9H0/yf12PAUXu9simtbC3Zvfqk6UbuKXSSteFBRjrhvTsVIbJo3oBAAb16KA9rp14sBIt8PMsB8NkAw6iO2AfaJ1aguj2ueE1QEYSPg9f1/vFeaMwYWBXnP+Xj3CoscUzCK7bG9yB5e3Cu7i6P84a1cuKi6Sc39Y0hQPt5GUy7RS2QBywj8P2LKywLhivIKi8r5cFIneXFEUwpKqj5dLSNTRMvr5zED3Ia/KTROCkPIx7to86EAmHQJi2CCsQB1JiIClpvCGv67FftgvxqjyW63kM79kJQEKhpFSe2+/vksYbzIWVnZG+NdeBnH1kr5RtbVUhMgzALixH7D/8lCyssArE53leFshFE/rhjCN6WeuUS33j6cLSCJBYa8I/PC4ms2HGVNf96XbjZZhChMvJcyYAAA/tSURBVC0QB7xiIGFnyl7n+W3/TUSW8gASFkuQeIwk0agvQBovaxBfyM+bXVhMW4QtEAfsE3n7OuRhCwm9Bl7ZEr3KJYVXh+XCckjjffn6E/HW8h2u5waBC9r8wW8T05ZhBeKA3QLx01MqE1w4vi9KiyM456jewU40tYBdThn8H9u/EmMdGiXKAHwhDHaFIEM2YAOEaYuwAnHCNpD56Wrr67JedSBEOG9Mn8DXlS6vIrMOpDhKuGnyCJw5yn/zvUIIYLc1BdLGXg7DJMEKxIHUGAhh1g9PsZ6HtUCyNUjLoLt0YXUoLcL1pw3zdW6+Fiv6w7Sx6Nu1HF+/f05ub5wHOAbCtEVYgThgtzCikQiG9+qUH2F8INIIoktyPVv+yri+2FvbZJOhjc3Z29jLYRgVViAO6CyQTJCtWb7fOhD9ufmLgUjF16msCFNH98YNp/uzmlofbIIwbQ9WIA7Yx9Iijx5Tvq+bLQVijk/SAtEty+tEPEQab6aQ72u/rhWOretbMxUlxk/slOFVeZaEYTIPKxAH7IOp34WWPK+bZZ9Gr85lAIDDupT5PseKgWRDIA+6VBTjD9PG4oSh3fNw9+zTsbQIH/7kNOtzYZi2BCsQB+yT8YwpkCyP0kOqOuD+b0wI1GLeKlrMk7/+K+P65ufGOaJ/t4p8i8AwWYEViE/SiE0nke0xOkKEKUcFWzc7YYFwxJdhGP+wAnHAHkLI1AJI2bZA0jGUgsrWoSSKb580OPwNGYZp1bACccC+4l+mXFjZtkHCyGlVogc87/NfTgl8L4Zh2g7cTNEBe+FX1GF6fnF1v0DXzbYFEiaTKl+FhAzDtG7yqkCI6EdEJIioh/mciOhPRLSWiJYQ0Xjl2CuJaI35/8psy2ZfjyOimdlvmDEVd190tOt1XrruBLxx08nW82yN0X+/+lh8fUIwZSZJtHNnDcIwjH/y5sIiov4AzgSwUdl8DoDh5v9jAdwH4Fgi6gbgfwBUwxjvFhHRK0KIfdmSzx4DCevCGjega9LzbNVanDisB040F5kKClsgDMOEIZ8WyO8B/ATJJboXAHhCGMwFUElEvQGcDWCWEGKvqTRmAciqA96+HkemguiFiFWJnmc5GIZpXeRFgRDR+QC2CCE+s+3qC2CT8nyzuc1pu+7a1xDRQiJauGvXrvBCZsgCsVOIg7TlrWvDSpJhmMyTNRcWEb0FQFeQ8DMAtwI4S3eaZptw2Z66UYgHATwIANXV1aEbENljIE5B9KAU4hgdZklbhmGYrCkQIcRk3XYiGg1gMIDPzHhAPwCLiWgiDMuiv3J4PwBbze2TbNvfy7jQCil1IBkrJCzAYbqAFpRiGKb1kHMXlhBiqRCipxBikBBiEAzlMF4IsR3AKwCuMLOxjgNwQAixDcCbAM4ioq5E1BWG9fJmduVMft5aWpmEgbOwGIYJQ6EVEr4G4FwAawHUAfgWAAgh9hLRrwAsMI/7pRBibzYFkS6sbxw3AEWRCEb0LNy1QNKFs7AYhglD3hWIaYXIxwLA9Q7HPQrg0RyJZTG0qiO+dWLm2nUU4iDNWVgMw4SBK9EdiIds7+FFPtbc8IItEIZhwsAKxAE5qOoq0NOhEMfoRBZvIUrHMEyhwgrEgexZIBm+YAZgC4RhmDCwAnEgW7PyQsx0SnTjLTzZGIYpXFiBOCAH1bbcwkTChegMw4SBFYgD8bjxN9ODaiEP0gUsGsMwBQgrEAeyldpaiIO0ffEshmEYP7ACcUC2Msm4C6sANQgH0RmGCQMrEAfiWeoPVYiBam5lwjBMGFiBOGHNyjOchVWAY/SAbhUAgD6V5XmWhGGY1kTeW5kUKnErCyuz1y1A/YHLjxuIIVUdcFLIFQ0ZhmmfsAJxYHgvo3li7y6ZnZUXYrV3JEI4eXhVvsVgGKaVwQrEge+dOhTHDemGCQO7ZfS6hac+GIZhwsExEAeiEcq48gAKMwbCMAwTBlYgOYYznRiGaSuwAsk1rD8YhmkjsAJhGIZhQsEKJMdwDIRhmLYCK5Acw/qDYZi2AiuQHFOIdSAMwzBhYAWSY1h9MAzTVmAFkmPYAGEYpq3ACiTHcB0IwzBtBVYgOYYtEIZh2gqsQBiGYZhQsALJMWyBMAzTVmAFkmM4BsIwTFuBFQjDMAwTClYgOYZdWAzDtBVYgeQY1h8Mw7QVWIHkGG5lwjBMW4EVSI5h9cEwTFuBFUiOYQOEYZi2AiuQHMMuLIZh2gqsQBiGYZhQsAJhGIZhQsEKJEcURdh1xTBM2yJvCoSIvk9Eq4jocyK6W9l+CxGtNfedrWyfYm5bS0Q350fq8My88WTcNvWIfIvBMAyTMYrycVMiOg3ABQDGCCEaiainuX0UgOkAjgTQB8BbRDTCPO1eAGcC2AxgARG9IoRYnnvpwzHysE4YeVinfIvBMAyTMfKiQABcC2CGEKIRAIQQO83tFwB41ty+nojWApho7lsrhFgHAET0rHlsq1EgDMMwbY18ubBGADiZiOYR0ftEdIy5vS+ATcpxm81tTtsZhmGYPJE1C4SI3gJwmGbXz8z7dgVwHIBjADxPREOgL9QW0Cs64XDfawBcAwADBgwILjjDMAzji6wpECHEZKd9RHQtgBeFEALAfCKKA+gBw7LorxzaD8BW87HTdvt9HwTwIABUV1drlQzDMAyTPvlyYb0M4HQAMIPkJQB2A3gFwHQiKiWiwQCGA5gPYAGA4UQ0mIhKYATaX8mL5AzDMAyA/AXRHwXwKBEtA9AE4ErTGvmciJ6HERxvAXC9ECIGAER0A4A3AUQBPCqE+Dw/ojMMwzAAQMa43Taprq4WCxcuzLcYDMMwrQoiWiSEqPY6jivRGYZhmFC0aQuEiHYB+DKNS/SAEZspNFiuYLBcwWC5gtEW5RoohKjyOqhNK5B0IaKFfsy4XMNyBYPlCgbLFYz2LBe7sBiGYZhQsAJhGIZhQsEKxJ0H8y2AAyxXMFiuYLBcwWi3cnEMhGEYhgkFWyAMwzBMKFiBaMjn4lVE9CgR7TSr9OW2bkQ0i4jWmH+7mtuJiP5kyrmEiMZnUa7+RPQuEa0wFwH7QSHIRkRlRDSfiD4z5brD3D7Y7Pa8hoieM1vgwGyT85wp1zwiGpQNuRT5okT0CRG9WmBybSCipUT0KREtNLcVwveskoj+SUQrze/a8fmWi4hGmu+T/H+QiG7Kt1zmvX5ofu+XEdEz5u8hd98xIQT/V/7DaJXyBYAhMHp0fQZgVA7vfwqA8QCWKdvuBnCz+fhmAL8xH58L4HUYXYyPAzAvi3L1BjDefNwJwGoAo/Itm3n9jubjYgDzzPs9D2C6uf1+ANeaj68DcL/5eDqA57L8ef4/AE8DeNV8XihybQDQw7atEL5njwO42nxcAqCyEORS5IsC2A5gYL7lgrGkxXoA5cp365u5/I5l9c1ujf8BHA/gTeX5LQBuybEMg5CsQFYB6G0+7g1glfn4AQCX6I7LgYz/grFCZMHIBqACwGIAx8IooCqyf6Yw+qkdbz4uMo+jLMnTD8DbMBqHvmoOKHmXy7zHBqQqkLx+lgA6mwMiFZJcNlnOAvBRIciFxDpJ3czvzKsAzs7ld4xdWKkU4uJVvYQQ2wDA/NvT3J4XWU3TdxyM2X7eZTPdRJ8C2AlgFgwLcr8QokVzb0suc/8BAN2zIReAPwD4CYC4+bx7gcgFGOvp/IeIFpGxhg6Q/89yCIBdAP5muv0eJqIOBSCXynQAz5iP8yqXEGILgN8C2AhgG4zvzCLk8DvGCiQVp0WtCpGcy0pEHQG8AOAmIcRBt0M127IimxAiJoQYC2PGPxHAES73zolcRHQegJ1CiEXq5nzLpXCiEGI8gHMAXE9Ep7gcmyvZimC4b+8TQowDUAvDNZRvuYybGbGE8wH8w+tQzbZsfMe6wljaezCAPgA6wPg8ne6dcblYgaTitqhVvthBRL0BwPwr15DPqaxEVAxDefxdCPFiIckGAEKI/QDeg+F3riQiuVyBem9LLnN/FwB7syDOiQDOJ6INAJ6F4cb6QwHIBQAQQmw1/+4E8BIMxZvvz3IzgM1CiHnm83/CUCj5lktyDoDFQogd5vN8yzUZwHohxC4hRDOAFwGcgBx+x1iBpFKIi1e9AuBK8/GVMOIPcvsVZtbHcQAOSJM60xARAXgEwAohxD2FIhsRVRFRpfm4HMaPagWAdwFc5CCXlPciAO8I0ymcSYQQtwgh+gkhBsH4Dr0jhLgs33IBABF1IKJO8jEMv/4y5PmzFEJsB7CJiEaam86AsTZQ3r//Jpcg4b6S98+nXBsBHEdEFebvU75fufuOZTPg1Fr/w8iiWA3Dl/6zHN/7GRj+zGYYM4arYPgp3wawxvzbzTyWANxryrkUQHUW5ToJhrm7BMCn5v9z8y0bgDEAPjHlWgbgF+b2ITBWs1wLw+VQam4vM5+vNfcPycFnOgmJLKy8y2XK8Jn5/3P5Hc/3Z2neayyAhebn+TKArgUiVwWAPQC6KNsKQa47AKw0v/tPAijN5XeMK9EZhmGYULALi2EYhgkFKxCGYRgmFKxAGIZhmFCwAmEYhmFCwQqEYRiGCQUrEIZxgIhiti6srp2Zieh7RHRFBu67gYh6hDjvbCK6nYi6EtFr6crBMF4UeR/CMO2WemG0SPGFEOL+bArjg5NhFJGdAuCjPMvCtANYgTBMQMz2JM8BOM3cdKkQYi0R3Q7gkBDit0R0I4DvAWgBsFwIMZ2IugF4FEahVx2Aa4QQS4ioO4wC0ioYBV6k3OsbAG6E0dp8HoDrhBAxmzzTYHSNHgKjN1IvAAeJ6FghxPnZeA8YBmAXFsO4UW5zYU1T9h0UQkwE8BcYPa7s3AxgnBBiDAxFAhhVw5+Y224F8IS5/X8AzBZGA8FXAAwAACI6AsA0GI0PxwKIAbjMfiMhxHNIrCEzGkZV8jhWHky2YQuEYZxxc2E9o/z9vWb/EgB/J6KXYbTkAIx2MF8DACHEO0TUnYi6wHA5XWhun0lE+8zjzwAwAcACo9URypFo2GdnOIzWGQBQIYSo8fH6GCYtWIEwTDiEw2PJVBiK4XwAPyeiI+HeTlt3DQLwuBDiFjdByFiStgeAIiJaDqC3uT7K94UQH7q/DIYJD7uwGCYc05S/c9QdRBQB0F8I8S6MBaUqAXQE8AFMFxQRTQKwWxhrqqjbz4HRQBAwGvRdREQ9zX3diGigXRAhRDWAmTDiH3fDaI44lpUHk23YAmEYZ8rNmbzkDSGETOUtJaJ5MCZhl9jOiwJ4ynRPEYDfCyH2m0H2vxHREhhBdNla+w4AzxDRYgDvw2jTDSHEciK6DcbKgREYHZqvB/ClRtbxMILt1wG4R7OfYTIOd+NlmICYWVjVQojd+ZaFYfIJu7AYhmGYULAFwjAMw4SCLRCGYRgmFKxAGIZhmFCwAmEYhmFCwQqEYRiGCQUrEIZhGCYUrEAYhmGYUPx/JNYEKGarLUoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8537f5ef28>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch a Smart Agent!\n",
    "\n",
    "In the next code cell, you will load the trained weights from file to watch a smart agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights from file\n",
    "agent = Agent(STATE_SIZE, ACTION_SIZE, 64,1234)\n",
    "agent.online_net.load_state_dict(torch.load('checkpoint.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f148e3b5198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    state = env.reset()\n",
    "    img = plt.imshow(env.render(mode='rgb_array'))\n",
    "    for j in range(200):\n",
    "        action = agent.act(state)\n",
    "        img.set_data(env.render(mode='rgb_array')) \n",
    "        plt.axis('off')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break \n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Explore\n",
    "\n",
    "In this exercise, you have implemented a DQN agent and demonstrated how to use it to solve an OpenAI Gym environment.  To continue your learning, you are encouraged to complete any (or all!) of the following tasks:\n",
    "- Amend the various hyperparameters and network architecture to see if you can get your agent to solve the environment faster.  Once you build intuition for the hyperparameters that work well with this environment, try solving a different OpenAI Gym task with discrete actions!\n",
    "- You may like to implement some improvements such as prioritized experience replay, Double DQN, or Dueling DQN! \n",
    "- Write a blog post explaining the intuition behind the DQN algorithm and demonstrating how to use it to solve an RL environment of your choosing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
